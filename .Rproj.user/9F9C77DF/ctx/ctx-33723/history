# Step 2: Impute categorical variables using mode imputation
# Define a function to calculate mode
calculate_mode <- function(x) {
ux <- unique(x)
ux[which.max(tabulate(match(x, ux)))]
}
# Apply mode imputation to categorical columns
categorical_cols <- sapply(train_data, function(x) is.factor(x) || is.character(x))
for (col in names(train_data)[categorical_cols]) {
# Impute missing values in train data
train_data[[col]][is.na(train_data[[col]])] <- calculate_mode(train_data[[col]])
# Impute missing values in test data (using mode from train data)
test_data[[col]][is.na(test_data[[col]])] <- calculate_mode(train_data[[col]])
}
# Step 3: Check again for missing values to confirm imputation
colSums(is.na(train_data))
colSums(is.na(test_data))
```
```
# Combine countries with less than 0.1% occurrence into "Other"
low_freq_countries <- names(native_country_freq[native_country_freq < (0.001 * nrow(train_data))])
# Check frequency of native-country levels
native_country_freq <- table(train_data$native_country)
# Combine countries with less than 0.1% occurrence into "Other"
low_freq_countries <- names(native_country_freq[native_country_freq < (0.001 * nrow(train_data))])
train_data$native_country <- ifelse(train_data$native_country %in% low_freq_countries, "Other", train_data$native_country)
test_data$native_country <- ifelse(test_data$native_country %in% low_freq_countries, "Other", test_data$native_country)
# Check the transformed country data
table(train_data$native_country)
```
```{r}
# Use chi-squared tests for categorical variables
chisq.test(table(train_data$sex, train_data$income))
chisq.test(table(train_data$marital_status, train_data$income))
# Use chi-squared tests for categorical variables
chisq.test(table(train_data$sex, train_data$income))
chisq.test(table(train_data$marital_status, train_data$income))
# Use chi-squared tests for categorical variables
chisq.test(table(train_data$sex, train_data$income))
# Step 3: Check again for missing values to confirm imputation
colSums(is.na(train_data))
colSums(is.na(test_data))
# Check frequency of native-country levels
native_country_freq <- table(train_data$native_country)
# Combine countries with less than 0.1% occurrence into "Other"
low_freq_countries <- names(native_country_freq[native_country_freq < (0.001 * nrow(train_data))])
train_data$native_country <- ifelse(train_data$native_country %in% low_freq_countries, "Other", train_data$native_country)
test_data$native_country <- ifelse(test_data$native_country %in% low_freq_countries, "Other", test_data$native_country)
# Check the transformed country data
table(train_data$native_country)
# Use chi-squared tests for categorical variables
chisq.test(table(train_data$sex, train_data$income))
chisq.test(table(train_data$marital_status, train_data$income))
# Plot distributions
boxplot(age ~ income, data = train_data, main = "Age vs Income")
library(car)
library(glmnet)
library(caret)
library(car)
library(glmnet)
library(caret)
# Convert the 'income' variable to a binary factor: 1 for ">50K", 0 for "<=50K"
train_data$income <- as.factor(ifelse(train_data$income == ">50K", 1, 0))
test_data$income <- as.factor(ifelse(test_data$income == ">50K", 1, 0))
# Train logistic regression model (1 represents income >50K)
logistic_model <- glm(income ~ ., family = binomial, data = train_data)
# Train logistic regression model (1 represents income >50K)
logistic_model <- glm(income ~ ., family = binomial, data = train_data)
# Predict on the test data
predicted_probs <- predict(logistic_model, test_data, type = "response")
# Convert probabilities to labels with a threshold of 0.5
predicted_labels <- ifelse(predicted_probs > 0.5, 1, 0)
# Evaluate model performance using a confusion matrix
confusion_matrix <- table(predicted_labels, test_data$income)
print(confusion_matrix)
# Compute the total error
total_error <- sum(predicted_labels != test_data$income) / nrow(test_data)
print(paste("Total Error: ", total_error))
library(car)
library(glmnet)
library(caret)
# Convert the 'income' variable to a binary factor: 1 for ">50K", 0 for "<=50K"
train_data$income <- as.factor(ifelse(train_data$income == ">50K", 1, 0))
test_data$income <- as.factor(ifelse(test_data$income == ">50K", 1, 0))
# Train logistic regression model (1 represents income >50K)
logistic_model <- glm(income ~ ., family = binomial, data = train_data)
# Predict on the test data
predicted_probs <- predict(logistic_model, test_data, type = "response")
# Convert probabilities to labels with a threshold of 0.5
predicted_labels <- ifelse(predicted_probs > 0.5, 1, 0)
# Evaluate model performance using a confusion matrix
confusion_matrix <- table(predicted_labels, test_data$income)
print(confusion_matrix)
# Compute the total error
total_error <- sum(predicted_labels != test_data$income) / nrow(test_data)
print(paste("Total Error: ", total_error))
library(glmnet)
install.packages("glmnet")
knitr::opts_chunk$set(echo = TRUE)
library(car)
library(car)
library(glmnet)
library(glmnet)
library(caret)
library(glmnet)
library(caret)
# Convert the 'income' variable to a binary factor: 1 for ">50K", 0 for "<=50K"
train_data$income <- as.factor(ifelse(train_data$income == ">50K", 1, 0))
test_data$income <- as.factor(ifelse(test_data$income == ">50K", 1, 0))
# Train logistic regression model (1 represents income >50K)
logistic_model <- glm(income ~ ., family = binomial, data = train_data)
# Predict on the test data
predicted_probs <- predict(logistic_model, test_data, type = "response")
# Convert probabilities to labels with a threshold of 0.5
predicted_labels <- ifelse(predicted_probs > 0.5, 1, 0)
# Evaluate model performance using a confusion matrix
confusion_matrix <- table(predicted_labels, test_data$income)
print(confusion_matrix)
# Compute the total error
total_error <- sum(predicted_labels != test_data$income) / nrow(test_data)
print(confusion_matrix)
# Compute the total error
total_error <- sum(predicted_labels != test_data$income) / nrow(test_data)
print(paste("Total Error: ", total_error))
print(confusion_matrix)
# Compute the total error
total_error <- sum(predicted_labels != test_data$income) / nrow(test_data)
print(paste("Total Error: ", total_error))
install.packages("reticulate")
install.packages("tensorflow")
install.packages("keras")
ibrary(tensorflow)
library(tensorflow)
install_tensorflow(method = "conda", envname = "r-tensorflow-compatible")
library(tensorflow)
install_tensorflow(method = "conda", envname = "r-tensorflow-compatible")
setwd("~/Desktop/ML Assignment 3")
library(tensorflow)
library(tensorflow)
use_condaenv("r-tensorflow-compatible", required = TRUE)
library(tensorflow)
use_condaenv("r-tensorflow-compatible", required = TRUE)
library(keras)  # YOU MIGHT WANT library(keras3)
use_condaenv("r-tensorflow-compatible", required = TRUE)
library(keras)  # YOU MIGHT WANT library(keras3)
tf$constant("Hello, TensorFlow!")
library(tensorflow)
use_condaenv("r-tensorflow-compatible", required = TRUE)
library(keras)  # YOU MIGHT WANT library(keras3)
tf$constant("Hello, TensorFlow!")
library(tensorflow)
use_condaenv("r-tensorflow-compatible", required = TRUE)
use_condaenv("r-tensorflow-compatible", required = TRUE)
library(keras)  # YOU MIGHT WANT library(keras3)
library(tensorflow)
use_condaenv("r-tensorflow-compatible", required = TRUE)
library(keras)  # YOU MIGHT WANT library(keras3)
tf$constant("Hello, TensorFlow!")
concrete <- read.csv("concrete.csv")
str(concrete)
concrete_train <- concrete[1:773,-9]
train_labels<-concrete[1:773,9]
concrete_test <- concrete[774:1030,-9]
test_labels <- concrete[774:1030,9]
concrete_train <- concrete[1:773,-9]
train_labels<-concrete[1:773,9]
concrete_test <- concrete[774:1030,-9]
test_labels <- concrete[774:1030,9]
concrete_train <- concrete[1:773,-9]
train_labels<-concrete[1:773,9]
concrete_test <- concrete[774:1030,-9]
test_labels <- concrete[774:1030,9]
concrete_train <- concrete[1:773,-9]
train_labels<-concrete[1:773,9]
concrete_test <- concrete[774:1030,-9]
test_labels <- concrete[774:1030,9]
concrete_train=scale(concrete_train)
col_means_train <- attr(concrete_train, "scaled:center")
col_stddevs_train <- attr(concrete_train, "scaled:scale")
#avoid data leakage
concrete_test <- scale(concrete_test, center = col_means_train, scale = col_stddevs_train)
concrete_train <- concrete[1:773,-9]
train_labels<-concrete[1:773,9]
concrete_test <- concrete[774:1030,-9]
test_labels <- concrete[774:1030,9]
concrete_train <- concrete[1:773,-9]
train_labels<-concrete[1:773,9]
concrete_test <- concrete[774:1030,-9]
test_labels <- concrete[774:1030,9]
```{r}
concrete_train=scale(concrete_train)
concrete_train=scale(concrete_train)
col_means_train <- attr(concrete_train, "scaled:center")
col_stddevs_train <- attr(concrete_train, "scaled:scale")
#avoid data leakage
concrete_test <- scale(concrete_test, center = col_means_train, scale = col_stddevs_train)
#avoid data leakage
concrete_test <- scale(concrete_test, center = col_means_train, scale = col_stddevs_train)
library(keras) # YOU MIGHT WANT library(keras3)
model <- keras_model_sequential() %>%
layer_dense(units = 10, activation = "relu", input_shape = c(dim(concrete_train)[2])) %>%
layer_dense(units = 1)
# Compile the model
model %>% compile(
optimizer = 'adam',
loss = 'mse'
)
library(keras) # YOU MIGHT WANT library(keras3)
model <- keras_model_sequential() %>%
layer_dense(units = 10, activation = "relu", input_shape = c(dim(concrete_train)[2])) %>%
layer_dense(units = 1)
library(keras) # YOU MIGHT WANT library(keras3)
model <- keras_model_sequential() %>%
layer_dense(units = 10, activation = "relu", input_shape = c(dim(concrete_train)[2])) %>%
layer_dense(units = 1)
set.seed(1)
history <- model %>% fit(concrete_train,
train_labels,
batch_size=50,
epochs = 500,
validation_data=list(concrete_test,test_labels))
library(tensorflow)
use_condaenv("r-tensorflow-compatible", required = TRUE)
use_condaenv("r-tensorflow-compatible", required = TRUE)
library(keras)  # YOU MIGHT WANT library(keras3)
library(keras)  # YOU MIGHT WANT library(keras3)
tf$constant("Hello, TensorFlow!")
NNs for regression: use an ANN to estimate the strength of concrete
```{r}
concrete_train=scale(concrete_train)
col_means_train <- attr(concrete_train, "scaled:center")
col_stddevs_train <- attr(concrete_train, "scaled:scale")
#avoid data leakage
concrete_test <- scale(concrete_test, center = col_means_train, scale = col_stddevs_train)
#avoid data leakage
concrete_test <- scale(concrete_test, center = col_means_train, scale = col_stddevs_train)
```{r}
library(keras) # YOU MIGHT WANT library(keras3)
model <- keras_model_sequential() %>%
layer_dense(units = 10, activation = "relu", input_shape = c(dim(concrete_train)[2])) %>%
layer_dense(units = 1)
library(keras) # YOU MIGHT WANT library(keras3)
model <- keras_model_sequential() %>%
layer_dense(units = 10, activation = "relu", input_shape = c(dim(concrete_train)[2])) %>%
layer_dense(units = 1)
remove.packages("keras")
install.packages("keras3")
library(keras3)
library(tensorflow)
use_condaenv("r-tensorflow-compatible", required = TRUE)
library(keras3)  # YOU MIGHT WANT library(keras3)
tf$constant("Hello, TensorFlow!")
concrete <- read.csv("concrete.csv")
str(concrete)
concrete <- read.csv("concrete.csv")
str(concrete)
concrete_train <- concrete[1:773,-9]
train_labels<-concrete[1:773,9]
concrete_test <- concrete[774:1030,-9]
test_labels <- concrete[774:1030,9]
concrete_train=scale(concrete_train)
col_means_train <- attr(concrete_train, "scaled:center")
col_stddevs_train <- attr(concrete_train, "scaled:scale")
#avoid data leakage
concrete_test <- scale(concrete_test, center = col_means_train, scale = col_stddevs_train)
library(keras3) # YOU MIGHT WANT library(keras3)
model <- keras_model_sequential() %>%
layer_dense(units = 10, activation = "relu", input_shape = c(dim(concrete_train)[2])) %>%
layer_dense(units = 1)
# Compile the model
model %>% compile(
optimizer = 'adam',
loss = 'mse'
)
model
set.seed(1)
history <- model %>% fit(concrete_train,
train_labels,
batch_size=50,
epochs = 500,
validation_data=list(concrete_test,test_labels))
set.seed(1)
history <- model %>% fit(concrete_train,
train_labels,
batch_size=50,
epochs = 500,
validation_data=list(concrete_test,test_labels))
plot(history)
set.seed(1)
history <- model %>% fit(concrete_train,
train_labels,
batch_size=50,
epochs = 500,
validation_data=list(concrete_test,test_labels))
set.seed(1)
history <- model %>% fit(concrete_train,
train_labels,
batch_size=50,
epochs = 500,
validation_data=list(concrete_test,test_labels))
set.seed(1)
history <- model %>% fit(concrete_train,
train_labels,
batch_size=50,
epochs = 500,
validation_data=list(concrete_test,test_labels))
set.seed(1)
history <- model %>% fit(concrete_train,
train_labels,
batch_size=50,
epochs = 500,
validation_data=list(concrete_test,test_labels))
reticulate::py_last_error()
reticulate::py_last_error()$r_trace$full_call
install.packages("keras3")
install.packages("tensorflow")
library(keras3)
library(tensorflow)
library(tensorflow)
library(keras3)
library(tensorflow)
install_tensorflow(method = "conda", envname = "r-tensorflow-compatible")
library(tensorflow)
use_condaenv("r-tensorflow-compatible", required = TRUE)
library(tensorflow)
use_condaenv("r-tensorflow-compatible", required = TRUE)
library(tensorflow)
use_condaenv("r-tensorflow-compatible", required = TRUE)
library(tensorflow)
use_condaenv("r-tensorflow-compatible", required = TRUE)
library(keras3)  # YOU MIGHT WANT library(keras3)
tf$constant("Hello, TensorFlow!")
concrete <- read.csv("concrete.csv")
str(concrete)
concrete_train <- concrete[1:773,-9]
train_labels<-concrete[1:773,9]
concrete_test <- concrete[774:1030,-9]
test_labels <- concrete[774:1030,9]
concrete_train=scale(concrete_train)
col_means_train <- attr(concrete_train, "scaled:center")
col_stddevs_train <- attr(concrete_train, "scaled:scale")
#avoid data leakage
concrete_test <- scale(concrete_test, center = col_means_train, scale = col_stddevs_train)
library(keras3) # YOU MIGHT WANT library(keras3)
model <- keras_model_sequential() %>%
layer_dense(units = 10, activation = "relu", input_shape = c(dim(concrete_train)[2])) %>%
layer_dense(units = 1)
# Compile the model
model %>% compile(
optimizer = 'adam',
loss = 'mse'
)
model
set.seed(1)
history <- model %>% fit(concrete_train,
train_labels,
batch_size=50,
epochs = 500,
validation_data=list(concrete_test,test_labels))
plot(history)
predictions=model %>% predict(concrete_test)
rmse= function(x,y){
return((mean((x - y)^2))^0.5)
}
rmse(predictions,test_labels)
knitr::opts_chunk$set(echo = TRUE)
library(dplyr)
library(dplyr)
library(caret)
# Define column names
column_names <- c("age", "workclass", "fnlwgt", "education", "education_num",
"marital_status", "occupation", "relationship", "race",
"sex", "capital_gain", "capital_loss", "hours_per_week",
"native_country", "income")
# Load the dataset with no headers and handle missing values (represented by ' ?')
adult_data <- read.csv("adult.data", header=FALSE, na.strings = " ?", col.names = column_names)
# Inspect the dataset
str(adult_data)
summary(adult_data)
View(adult_data)
library(dplyr)
library(caret)
column_names <- c("age", "workclass", "fnlwgt", "education", "education_num",
"marital_status", "occupation", "relationship", "race",
"sex", "capital_gain", "capital_loss", "hours_per_week",
"native_country", "income")
# Load the dataset with no headers and handle missing values (represented by ' ?')
adult_data <- read.csv("adult.data", header=FALSE, na.strings = " ?", col.names = column_names)
# Inspect the dataset
str(adult_data)
summary(adult_data)
View(adult_data)
# Load the dataset with no headers and handle missing values (represented by ' ?')
adult_data <- read.csv("adult.data", header=FALSE, na.strings = " ?", col.names = column_names)
sapply(adult_data, class)
sapply(adult_data, class)
# Set the random seed for reproducibility
set.seed(123)
library(caret)
# Split the data (using caret's createDataPartition)
trainIndex <- createDataPartition(adult_data$income, p = 0.8, list = FALSE)
train_data <- adult_data[trainIndex, ]
test_data <- adult_data[-trainIndex, ]
# Check the dimensions of training and testing sets
dim(train_data)
dim(test_data)
# Load necessary libraries
library(caret)
library(dplyr)
# Check for missing values in the train and test datasets
colSums(is.na(train_data))
colSums(is.na(test_data))
# Step 1: Impute numeric variables using 'preProcess' for median imputation
numeric_cols <- sapply(train_data, is.numeric)  # Identify numeric columns
# Apply median imputation to numeric columns
preProcValues <- preProcess(train_data[, numeric_cols], method = "medianImpute")
train_data[, numeric_cols] <- predict(preProcValues, train_data[, numeric_cols])
test_data[, numeric_cols] <- predict(preProcValues, test_data[, numeric_cols])
# Step 2: Impute categorical variables using mode imputation
# Define a function to calculate mode
calculate_mode <- function(x) {
ux <- unique(x)
ux[which.max(tabulate(match(x, ux)))]
}
# Apply mode imputation to categorical columns
categorical_cols <- sapply(train_data, function(x) is.factor(x) || is.character(x))
for (col in names(train_data)[categorical_cols]) {
# Impute missing values in train data
train_data[[col]][is.na(train_data[[col]])] <- calculate_mode(train_data[[col]])
# Impute missing values in test data (using mode from train data)
test_data[[col]][is.na(test_data[[col]])] <- calculate_mode(train_data[[col]])
}
# Step 3: Check again for missing values to confirm imputation
colSums(is.na(train_data))
colSums(is.na(test_data))
# Check frequency of native-country levels
native_country_freq <- table(train_data$native_country)
# Combine countries with less than 0.1% occurrence into "Other"
low_freq_countries <- names(native_country_freq[native_country_freq < (0.001 * nrow(train_data))])
train_data$native_country <- ifelse(train_data$native_country %in% low_freq_countries, "Other", train_data$native_country)
test_data$native_country <- ifelse(test_data$native_country %in% low_freq_countries, "Other", test_data$native_country)
# Check the transformed country data
table(train_data$native_country)
# Use chi-squared tests for categorical variables
chisq.test(table(train_data$sex, train_data$income))
chisq.test(table(train_data$marital_status, train_data$income))
# Plot distributions
boxplot(age ~ income, data = train_data, main = "Age vs Income")
library(car)
library(glmnet)
library(caret)
# Convert the 'income' variable to a binary factor: 1 for ">50K", 0 for "<=50K"
train_data$income <- as.factor(ifelse(train_data$income == ">50K", 1, 0))
library(car)
library(glmnet)
library(caret)
# Convert the 'income' variable to a binary factor: 1 for ">50K", 0 for "<=50K"
train_data$income <- as.factor(ifelse(train_data$income == ">50K", 1, 0))
test_data$income <- as.factor(ifelse(test_data$income == ">50K", 1, 0))
# Train logistic regression model (1 represents income >50K)
logistic_model <- glm(income ~ ., family = binomial, data = train_data)
# Train logistic regression model (1 represents income >50K)
logistic_model <- glm(income ~ ., family = binomial, data = train_data)
# Predict on the test data
predicted_probs <- predict(logistic_model, test_data, type = "response")
# Convert probabilities to labels with a threshold of 0.5
predicted_labels <- ifelse(predicted_probs > 0.5, 1, 0)
# Evaluate model performance using a confusion matrix
confusion_matrix <- table(predicted_labels, test_data$income)
print(confusion_matrix)
# Compute the total error
total_error <- sum(predicted_labels != test_data$income) / nrow(test_data)
print(paste("Total Error: ", total_error))
# Separate the training data by income class
over_50k <- train_data[train_data$income == ">50K", ]
under_50k <- train_data[train_data$income == "<=50K", ]
# Down-sample the majority class to match the size of the minority class
set.seed(123)
under_50k_sample <- under_50k[sample(nrow(under_50k), nrow(over_50k)), ]
# Combine the two datasets to create a balanced training set
balanced_train_data <- rbind(over_50k, under_50k_sample)
# Re-train the logistic regression model on balanced data
logistic_model <- glm(income ~ ., family = binomial, data = train_data)
# Re-train the logistic regression model on balanced data
logistic_model <- glm(income ~ ., family = binomial, data = train_data)
# Predict on the original test data
balanced_predicted_probs <- predict(logistic_model, test_data, type = "response")
balanced_predicted_labels <- ifelse(balanced_predicted_probs > 0.5, ">50K", "<=50K")
# Evaluate balanced model performance
balanced_confusion_matrix <- table(balanced_predicted_labels, test_data$income)
print(balanced_confusion_matrix)
# Compute the total error for balanced model
balanced_total_error <- sum(balanced_predicted_labels != test_data$income) / nrow(test_data)
print(paste("Balanced Model Total Error: ", balanced_total_error))
install.packages("partykit")
library(partykit)
install.packages("partykit")
library(partykit)
install.packages("partykit")
install.packages("partykit")
knitr::opts_chunk$set(echo = TRUE)
library(partykit)
library(partykit)
knitr::opts_chunk$set(echo = TRUE)
library(partykit)
install.packages("partykit")
library(partykit)
library(partykit)
library(C50)
install.packages("partykikt")
install.packages("partykit")
install.packages("C50")
